test.build.data=/home/attu7372/benchmarks/testdfsio
resultDir=/home/attu7372/tmp
#nrOcc.write=50
#nrOcc.read=50
#nrFiles=1 2 4 6 8 10 20 30
#size=64MB 128MB 256MB 512MB 1GB 2GB 4GB
#bufferSize=4096 8192 16284 32568
#compression=nil org.apache.hadoop.io.compress.SnappyCodec org.apache.hadoop.io.compress.Lz4Codec
#storagePolicy=nil LAZY_PERSIST
#dfs.blocksize=64m 128m 256m 512m 1g
#dfs.replication=1 2 3 4 5 6
operation=write resize read random backward skip shortcircuit
nrOcc.write=2
nrOcc.resize=2
resize.size=1MB 2MB
nrOcc.read=3
nrFiles=8 10
size=64MB 128MB
skipSize=1MB 2MB
bufferSize=4096 8192
dfs.blocksize=64m 128MB
dfs.replication=1 2 3
java.home=/opt/jdk1.8.0_231
jarFile=../target/TestDFSIO-0.0.1-jar-with-dependencies.jar
mapreduce.job.running.map.limit=4